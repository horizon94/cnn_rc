\section{Deep Feedforward Neural Networks}

There are many different algorithms to choose from when trying to learn a relation classifier. A widely used datastructure is the \emph{neural network}, which have been used extensively in recent years with significant results in several research areas including NLP. The recent work on neural networks in NLP and specifically RC will be covered in \autoref{related_works}. This section covers the definition of a deep feedforward neural network and how it is trained to approximate $h$ through derivatives. T

\subsection{Definition}

A deep feedforward neural network is a datastructure which can be used to learn a function $h : \mathcal(X) \mapsto \mathcal{Y}$ from a set of training data $D_{train}$. Usually, the term neural network also encompasses the algorithms which are used to build the datastructure and approximate the function $h$. A common way to describe neural networks is to describe each word:

The word `network' is used because the datastructure represents a series of functions which are chained together to form a network. This layering of functions forms a directed graph $f(0) \mapsto f(1) \ldots f(n-1) \mapsto {f-n}$ which begins with the input space $\mathcal{X}$ and ends with the output $\mathcal{Y}$.  
Each layer in the network $f(i)$ receives input from the previous layer $f(i-1)$. The first layer $f(0)$ is called the \emph{input layer}, while the final layer is called the \emph{output layer}. Layers in between are called \emph{hidden layers}. The layers are called hidden because they are not defined by the training data and must be learned by the individual network\citep[chapter 6]{dl_book}. 

The word `neural' is used to describe these structures because they take inspiration from models of biological brains. As an example, consider a network layer where the input is a vector $v$ of length $n$, which also defines the \emph{width} of the network.We can apply an entire vector-to-vector function $f(v)$ which outputs a new vector, the input for the next layer. We can also deconstruct $f(v)$ to its individual components:

$$ f(v) =  [f_{v}^{0};f_{v}^{1}\ldots;f_{v}^{n}]^T $$ 

where $f_v^{i}$ act in parallel on the input vector. These components are now vector-to-scalar functions. The output of such a subfunction $f_{v}^{i}$ is inspired by a \emph{neuron} - or \emph{unit} - in the brain. The strength of the connection between an input and a neuron is called a \emph{weight}. All weights for a particular neuron are summed to form the \emph{activation} of the neuron. The activation is then a linear combination of the inputs determined by the weights $w_{j0}, w_{j1} \ldots w_{jn}$:

$$
    f_{v}^{i} =  \sum_{j=0}{n} v_j * w_{vj} 
$$

\subsubsection{Activation and Bias}
The \emph{activation function}, which is inspired by neuron activation, is applied to the above mentioned activation to introduce a non-linearity to the activation. The functions usually squeeze the input into a certain interval which is analogous to neurons ``firing'' in the brain when they have received enough signal to pass a threshold. In order for the threshold to be specific to each neuron a \emph{bias parameter} $b$ is added to the transformation described above:

$$
    f_{v}^{i} =  \sum_{j=0}{n} v_j * w_{vj} + b 
$$

% TODO insert neural network graph

As I will show in \autoref{nn_optimization} the derivative of the activation function is an important factor in choosing which activation function to use.

The traditional activation function is the \emph{logistic sigmoid} function, which is a smooth ``S''-shaped function which centers around zero. The derivative is simple and easy to compute. However, the sigmoid suffers not being centered around zero, which is a problem for gradient-based optimization.\citep[p. 66]{dlbook}. To compensate for this problem, the \emph{hyperbolic tangent} function is used, which is centered around zero. Both functions suffer from \emph{saturation} which is also a problem for optimization \cite{activations}. A third option is then the \emph{rectified linear unit} (ReLU), which does not saturate. All three and their derivatives are shown below:

\begin{center}
\fbEpsfig{activation_functions}{\textwidth}{htbp}
\end{center}

% sigmoid $\frac{ds}{dx} = S(x) * (1 - S(x))$


%Notice that the function $h : \mathcal{X} \mapsto \mathcal{Y}$ will be equal to () 

The word `deep' is used when the number of hidden layers are more than zero. Accordingly, this number is called the \emph{depth} of the network. A network with no hidden layers - so that the input layer is directly connected to the output layer - is commonly called a \emph{perceptron}. While it is true that a single layer hidden network can approximate any function, it has been shown that increasing the depth greatly reduces the number of neurons needed in the network compared to a single layer network. % insert reference

Finally, the word `feedforward' is used to describe that the network has no connections that leads back to previous layers. The information flows in one direction through the network when it is being activated. A network that has information from the output flowing back into the network is called a \emph{recurrent neural net}. 

\subsection{Optimization}
\label{nn_optimization}

The question remains: how do we use the network to approximate $h:\mathcal{X}\mapsto{Y}$? Consider a supervised learning problem where $h$ maps each input $x_i$ to a single discrete output label $y_i \in \mathcal{Y}$. We can construct the output layer of the network such that each label has a corresponding output neuron. To find out which $y_i$ the network predicts from $x_i$ we inspect the activations of the neurons. One way of interpreting the values is as a probability $P(Y = y_i | X = x_i)$. 

%% TODO FINISH THIS SHIT 

If we design the output layer so that it represents a probability distribution over the labels in $\mathcal{Y}$

Because the learning problem is supervised, each $x_i$ which is in $D_{train}$ already have a given

\subsubsection{Objective function}


\subsection{Regularization}

\subsubsection{L2 Constraints}

\subsubsection{Early Stopping}

A non-intrusive way of limiting overfitting on the training set is to continually measure the performance of the classification function on a set of validation data for which we can measure the loss without updating the network. When the validation loss stops decreasing, we record the number of training iterations run on the network. This method is called \emph{early stopping}. The validation data must be independent from the training data and the test data which is used to estimate the generalization error. Early stopping can be applied to any neural network. A drawback of the method is that the validation data is not used for training. A way to deal with this problem is to use the validation data to find the number of training iterations, and then re-train the network with all the available data. The full pseudocode for the algorithm is detailed in \citep[p. 242]{dl_book}. 


\subsection{Word Embeddings}
\label{sec:word_embeddings}

Lorem ipsum dolor

\input{conv_nets.tex}