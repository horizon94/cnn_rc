
\section{Related Works}

This section describes recent related work in the area of relation extraction and classification. The focus of the section is the recent shift in tendency from feature-based systems to neural systems which require less (but arguably still some) feature engineering and domain knowledge.  


conferences:
acl
https://nips.cc/
icml
aistats

\subsection{Feature Engineered Systems}

http://www.aclweb.org/anthology/P14-2011
Tree kernels: 

With features such as:

Entity arguments types concatenated
Mention type concatenated

Sub entity type concatenated

N-grams

Phrase chunking 

Syntactico-semantic structure such as: premodifiers, possesive, preposition, formulaic and verbal

Relative positions

Contextual information

Lexical semantics

Treebank aka parse trees 

\subsection{Neural Networks}

WORD EMBEDDINGS
Mikolov et al., 2013b


Recursive Neural Networks:

kinda like parse trees for encoding structure between long sentences

Data augmentations and deeper RNN's
Also uses FEATURES as ``channels'':
POS tags
Grammatical relations
WordNet hypernbyms


CONVOLUTIONS:

Attention mechanisms
Word-pair features ? 

N-grams as convolutions:
Nguyen & Grishman
vector-cnn

learned outputs
CR-CNN, dos Santos et al.


Domain adaptations


Factor-based compositional embedding
models

Classifying Relations via Long Short Term Memory Networks
along Shortest Dependency Paths
https://pdfs.semanticscholar.org/0f44/366c1e1446cfd51258c68bd1da14fe9c7f10.pdf



Improved re- lation classification by deep recurrent neural net- works with data augmentation
https://arxiv.org/pdf/1601.03651.pdf


\subsection{Supervised vs. Semi-supervised}

Semi-supervised with clustering:

https://www.cs.nyu.edu/~asun/pub/ACL11-FinalVersion.pdf


Main points. 


    