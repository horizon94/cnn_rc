
\chapter{Related Works}
\label{chap:related_works}

Applications of deep neural networks to NLP have been a very active area of research in the past two decades. In relation classification, an abundance of work have gone into improving results on common datasets such as SemEval 2010 and the ACE 2005. 

This chapter presents related work in the area of relation extraction and classification. The focus of the chapter is the shift in tendency from heavily hand-crafted \emph{feature-enginereed systems} to neural networks with unsupervised pre-training which require considerably less task-specific feature-engineering. These neural networks are commonly called \emph{feature-learned systems}. Additionally, the chapter also covers approaches that uses supervised learning and approaches which try to use additional unlabeled data during or after the training process.  

It is important to notice that the definition \emph{feature-based system} -  which is used in many RE and RC papers such as \citep{re_cnn}, \citep{re_survey} and \citep{re_lstm} - is kind of a misnomer. What it usually specifically means is that the features which are used in the learning system are crafted with linguistic knowledge, and that they are not learned by another system. Such features might measure the shape of the word, the words around other words, which specific word group a word belongs to, which part of the sentence the word belong to and so on. Neural networks also use features. These features may not be hand-crafted, or they may be called a representation instead, but they are still features. Word vectors, which are the common input structure used for neural networks in NLP, is both a representation and a set of features for each word which is learnt from an unsupervised task. In neural network terminology, the words features and representation are often used interchangeably. The systems also overlap; for example, \citep{zeng2014} combines a word-vector with "traditionally" extracted features as input for a CNN.


\input{related_works/supervised} 
\input{related_works/semisupervised.tex}


